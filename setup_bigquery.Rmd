---
title: "setup_bigquery"
author: "Justin Marciszewski"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

https://cloud.google.com/bigquery/docs/arima-speed-up-tutorial


## Set Constants 

```{r set-constants}
project_id <- Sys.getenv("PROJECT_ID")
dataset_id <- "bqml_tutorial"
table_id <- ""
```


## load packages 

```{r load-packages}
library(glue)
library(gargle)
library(bigrquery)
```


## Authenticate with ADC 


```{r auth}
credentials_app_default(scopes="https://www.googleapis.com/auth/cloud-platform")
```


## Create dataset 


```{r}
bq_dataset <- bq_dataset(project_id, dataset_id)

if (!bq_dataset_exists(bq_dataset)) {
  print(glue("Dataset '{dataset_id}' does not exist, creating..."))
  bq_dataset_create(bq_dataset)
  print(glue("Dataset '{dataset_id}' created."))
} else {
  print(glue("Dataset '{dataset_id}' already exists."))
}
```



```{r}
# Create a BigQuery table
# bq_table <- bq_table(project_id, dataset_id, table_id)
# 
# if (!bq_table_exists(bq_table)) {
#   print(glue("Table '{table_id}' does not exist, creating..."))
#   bq_table_create(bq_table)
#   print(glue("Table '{table_id}' created."))
# } else {
#   print(glue("Table '{table_id}' already exists."))
# }
# 
# # Upload the data frame to the BigQuery table
# bq_table_upload(bq_table, values = dataframe)
```



```sql
CREATE OR REPLACE TABLE
bqml_tutorial.nyc_citibike_time_series AS
WITH input_time_series AS
(
SELECT
start_station_name,
EXTRACT(DATE FROM starttime) AS date,
COUNT(*) AS num_trips
FROM
`bigquery-public-data`.new_york.citibike_trips
GROUP BY
start_station_name, date
)
SELECT table_1.*
FROM input_time_series AS table_1
INNER JOIN (
SELECT start_station_name,  COUNT(*) AS num_points
FROM input_time_series
GROUP BY start_station_name) table_2
ON
table_1.start_station_name = table_2.start_station_name
WHERE
num_points > 400
```